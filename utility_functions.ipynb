{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86a128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "\n",
    "# test_start_time_point must be in the index of df\n",
    "def get_train_test_data(df, test_start_time_point):\n",
    "    train_data = df.loc[:test_start_time_point].iloc[:-1]\n",
    "    test_data = df.loc[test_start_time_point:]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def get_rank_demeaned_normalized_signal(raw_signal):\n",
    "    signal_rank = raw_signal.rank(axis=1)\n",
    "    signal_mean = raw_signal.rank(axis=1).mean(axis=1)\n",
    "    demeaned_signal = signal_rank.subtract(signal_mean, axis=0)\n",
    "    return demeaned_signal.divide(demeaned_signal.abs().sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "def get_gross_returns_and_net_returns(signal_weights, px):\n",
    "    asset_returns = px / px.shift() - 1\n",
    "    weighted_returns = signal_weights.shift() * asset_returns\n",
    "    gross_returns = weighted_returns.sum(axis=1)\n",
    "    turnover = (signal_weights.fillna(0) - signal_weights.shift().fillna(0)).abs().sum(axis=1)\n",
    "    tcost_bps = 20 # (commission + slippage)\n",
    "    net_returns = gross_returns.subtract(turnover * tcost_bps * 1e-4, fill_value = 0)\n",
    "    return gross_returns, net_returns\n",
    "\n",
    "\n",
    "def calculate_covariance_directly(ser_1, ser_2):\n",
    "    available_1 = ser_1.notna()\n",
    "    available_2 = ser_2.notna()\n",
    "    \n",
    "    common_1 = ser_1[available_1][available_2]\n",
    "    common_2 = ser_2[available_1][available_2]\n",
    "    \n",
    "    if common_1.shape[0] <= 1 or common_2.shape[0] <= 1:\n",
    "        return np.nan\n",
    "    \n",
    "    mean_1 = common_1.mean()\n",
    "    demeaned_1 = common_1 - mean_1\n",
    "    \n",
    "    mean_2 = common_2.mean()\n",
    "    demeaned_2 = common_2 - mean_2\n",
    "    \n",
    "    return (demeaned_1 * demeaned_2).sum() / (demeaned_1.shape[0] - 1)\n",
    "\n",
    "\n",
    "# Using pd.corrwith() yields a large number of hardware-related warnings so I implemented my \n",
    "# own version.\n",
    "def calculate_correlation_directly(ser_1, ser_2):\n",
    "    cov = calculate_covariance_directly(ser_1, ser_2)\n",
    "    \n",
    "    if cov == np.nan:\n",
    "        return np.nan\n",
    "\n",
    "    available_1 = ser_1.notna()\n",
    "    available_2 = ser_2.notna()\n",
    "    \n",
    "    common_1 = ser_1[available_1][available_2]\n",
    "    common_2 = ser_2[available_1][available_2]\n",
    "    \n",
    "    if len(common_1) <= 1 or len(common_2) <= 1:\n",
    "        return np.nan\n",
    "    \n",
    "    return cov / (common_1.std() * common_2.std())\n",
    "\n",
    "\n",
    "# returns pair in the form of (alpha, beta); nan values in dependent_series or independent_series are ignored;\n",
    "# neither can contain inf\n",
    "def get_alpha_beta_to_asset(dependent_series, independent_series):\n",
    "    cov = calculate_covariance_directly(dependent_series, independent_series)\n",
    "    \n",
    "    non_na_dependent_series = dependent_series[dependent_series.notna() & independent_series.notna()]\n",
    "    non_na_independent_series = independent_series[\n",
    "        dependent_series.notna() & independent_series.notna()]\n",
    "    \n",
    "    beta = cov / non_na_independent_series.var()\n",
    "    alpha = (non_na_dependent_series - non_na_independent_series * beta).mean()\n",
    "    return alpha, beta\n",
    "\n",
    "\n",
    "def get_decorrelated_returns(strat_returns, benchmark_asset_returns):\n",
    "    non_na_period_strat_returns = strat_returns[strat_returns.notna() & benchmark_asset_returns.notna()]\n",
    "    non_na_period_benchmark_rets = benchmark_asset_returns[\n",
    "        strat_returns.notna() & benchmark_asset_returns.notna()]\n",
    "    _, beta = get_alpha_beta_to_asset(non_na_period_strat_returns, non_na_period_benchmark_rets)\n",
    "    return strat_returns - beta * benchmark_asset_returns\n",
    "\n",
    "\n",
    "def get_max_drawdown(net_returns):\n",
    "    cumulative_net_returns = net_returns.cumsum()\n",
    "    drawdowns = cumulative_net_returns / cumulative_net_returns.expanding(min_periods=1).max() - 1\n",
    "    return drawdowns[drawdowns != float('-inf')].min()\n",
    "\n",
    "\n",
    "def get_max_drawdown_duration(net_returns, hours_freq):\n",
    "    cumulative_net_returns = net_returns.cumsum()\n",
    "    \n",
    "    peak = cumulative_net_returns.expanding(min_periods=1).max()\n",
    "    \n",
    "    max_drawdown_duration = 0\n",
    "    current_drawdown_duration = 0\n",
    "    \n",
    "    for dt in cumulative_net_returns.index:\n",
    "        if cumulative_net_returns[dt] >= peak[dt]:\n",
    "            current_drawdown_duration = 0\n",
    "        else:\n",
    "            current_drawdown_duration += 1\n",
    "            max_drawdown_duration = max(max_drawdown_duration, current_drawdown_duration)\n",
    "    return max_drawdown_duration * hours_freq / 24\n",
    "\n",
    "\n",
    "# trade_hours_freq = 4, 8, 12, 24 (for 1 day), ...\n",
    "def get_strategy_stats(net_returns, trade_hours_freq, input_prices):\n",
    "    bitcoin_returns_over_period = input_prices['BTCUSDT'] / input_prices['BTCUSDT'].shift() - 1\n",
    "    \n",
    "    alpha, beta = get_alpha_beta_to_asset(net_returns.iloc[2:],\n",
    "                                          bitcoin_returns_over_period.iloc[2:])\n",
    "    decorrelated_returns = get_decorrelated_returns(net_returns, bitcoin_returns_over_period)\n",
    "    \n",
    "    res = {\n",
    "        \"avg returns\": net_returns.mean() * 24 / trade_hours_freq * 365,\n",
    "        \"decorrelated avg returns\": decorrelated_returns.mean() * 24 / trade_hours_freq * 365,\n",
    "        \"volatility\": net_returns.std() * np.sqrt(24 / trade_hours_freq * 365),\n",
    "        \"sharpe ratio\": net_returns.mean() / net_returns.std() * np.sqrt(24 / trade_hours_freq * 365),\n",
    "        \"decorrelated sharpe ratio\": decorrelated_returns.mean() / decorrelated_returns.std() * np.sqrt(24 / trade_hours_freq * 365),\n",
    "        \"max drawdown\": get_max_drawdown(net_returns),\n",
    "        \"max drawdown duration\": get_max_drawdown_duration(net_returns, trade_hours_freq),\n",
    "        \"alpha_BTC\": alpha,\n",
    "        \"beta_BTC\": beta,\n",
    "    }\n",
    "    return res\n",
    "\n",
    "\n",
    "# For example, proportion_lo = 0.1 and proportion_hi = 0.1 makes the top and bottom 10% be the values at the\n",
    "# 90th and 10th percentiles, respectively.\n",
    "def get_winsorized_signal(raw_signal, proportion_lo, proportion_hi):\n",
    "    winsorized_signal = raw_signal.apply(lambda row: winsorize(\n",
    "        row, limits=[proportion_lo, proportion_hi]), axis=1, result_type='expand')\n",
    "    winsorized_signal.columns = raw_signal.columns\n",
    "    return winsorized_signal\n",
    "\n",
    "\n",
    "# For example, proportion_lo = 0.1 and proportion_hi = 0.1 makes the top and bottom 10% be removed.\n",
    "def get_truncated_signal(raw_signal, proportion_lo, proportion_hi):\n",
    "    quantile_lo = raw_signal.quantile(proportion_lo, axis=1)\n",
    "    mask_lo = raw_signal.lt(quantile_lo, axis=0)\n",
    "\n",
    "    quantile_hi = raw_signal.quantile(1-proportion_hi, axis=1)\n",
    "    mask_hi = raw_signal.gt(quantile_hi, axis=0)\n",
    "\n",
    "    return raw_signal.mask(mask_lo).mask(mask_hi)\n",
    "\n",
    "\n",
    "# For example, proportion_lo = 0.1 and proportion_hi = 0.1 makes the middle 80% of the data be removed.\n",
    "def get_rank_thresholded_signal(raw_signal, proportion_lo, proportion_hi):\n",
    "    quantile_lo = raw_signal.quantile(proportion_lo, axis=1)\n",
    "    mask_above = raw_signal.gt(quantile_lo, axis=0)\n",
    "\n",
    "    quantile_hi = raw_signal.quantile(1-proportion_hi, axis=1)\n",
    "    mask_below = raw_signal.lt(quantile_hi, axis=0)\n",
    "    \n",
    "    return raw_signal.mask(mask_above & mask_below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8827c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
